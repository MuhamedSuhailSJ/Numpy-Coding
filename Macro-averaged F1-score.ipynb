{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhamedSuhailSJ/Numpy-Coding/blob/main/Macro-averaged%20F1-score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06f22e03-17d2-45c2-95a4-b617e45a6339"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i9LXloxlIWr"
      },
      "source": [
        "### 1. Macro-averaged F1-score\n",
        "\n",
        "Implement the `macro_averaged_f1_score()` function which computes the Macro-averaged F1 score for a multi-class classification problem.\n",
        "\n",
        "\n",
        "$$\\text{Precision (P) = }\\frac{TP}{TP+FP}$$\n",
        "<br>\n",
        "$$\\text{Recall (R) = }\\frac{TP}{TP+FN}$$\n",
        "<br>\n",
        "$$\\text{F1-score = }\\frac{2PR}{P+R}$$\n",
        "<br>\n",
        "$$\\text{Macro-averaged F1-score = }\\frac{\\text{Sum of F1-scores of all classes }}{\\text{Number of classes}}$$\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`actual_Y`** :  Actual labels of instances.\n",
        "    * A 1D numpy array of chars\n",
        "    * Array shape: (number of instances, )\n",
        "* **`predicted_Y`**: Predicted labels of instances.\n",
        "    * A 1D numpy array of chars\n",
        "    * Array shape: (number of instances, )\n",
        "    * Assume that `predicted_Y` does not have labels which are not in `actual_Y`\n",
        "\n",
        "\n",
        "**Returns**:\n",
        "Macro-averaged F1-score (A float value)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03aeced1-552d-46f5-910b-9f10ff01836f"
      },
      "source": [
        "def macro_averaged_f1_score(actual_Y, predicted_Y):\n",
        "  unique_class_actual = np.unique(actual_Y)\n",
        "  total_class_score = 0\n",
        "  for class_label in unique_class_actual:\n",
        "    compare1 = predicted_Y == class_label\n",
        "    compare2 = actual_Y == class_label\n",
        "    predicted_positive_count = np.count_nonzero(compare1)\n",
        "    actual_positive_count = np.count_nonzero(compare2)\n",
        "\n",
        "    true_positive = np.logical_and(actual_Y == class_label,predicted_Y==class_label)\n",
        "    true_positive_count = np.count_nonzero(true_positive)\n",
        "\n",
        "    class_precision = 0\n",
        "    class_recall = 0\n",
        "    class_f1_score = 0\n",
        "    if(true_positive_count!=0):\n",
        "      class_precision = true_positive_count/predicted_positive_count\n",
        "      class_recall = true_positive_count/actual_positive_count\n",
        "      class_f1_score = (2*class_precision*class_recall)/(class_precision + class_recall)\n",
        "    total_class_score += class_f1_score\n",
        "  return total_class_score/unique_class_actual.shape[0]\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15FKlXP0n8MK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c22b1c-75a8-43aa-a3d8-32477fbb7548"
      },
      "source": [
        "actual_Y = np.array([\"A\",\"A\",\"B\",\"C\",\"C\"])\n",
        "predicted_Y = np.array([\"A\",\"B\",\"B\",\"C\",\"B\"])\n",
        "f1_score = macro_averaged_f1_score(actual_Y, predicted_Y)\n",
        "print(np.round(f1_score, 3))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL-PvZB-pKpn"
      },
      "source": [
        "**Expected Output**:\n",
        "```\n",
        "0.611\n",
        "```"
      ]
    }
  ]
}